import streamlit as st
import kss
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from kiwipiepy import Kiwi
import re

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ê°•ì˜ ë…¸íŠ¸ ìš”ì•½ ì„œë¹„ìŠ¤", layout="wide")

# --------------------------------------------------------------------------
# [1] ì‚¬ìš©ì ì›ë³¸ ë¶„ì„ê¸° ë¡œì§ (ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)
# --------------------------------------------------------------------------

@st.cache_resource
def get_kiwi():
    return Kiwi()

kiwi = get_kiwi()

def noun_tokenizer(text):
    """Kiwië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬(NNG, NNP)ë§Œ ì¶”ì¶œ"""
    tokens = kiwi.tokenize(text)
    nouns = []
    for token in tokens:
        if token.tag in ['NNG', 'NNP']:
            if len(token.form) > 1: 
                nouns.append(token.form)
    return nouns

def extract_keywords(text, num_keywords=10):
    """TF-IDFë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ"""
    tfidf_vectorizer = TfidfVectorizer(tokenizer=noun_tokenizer)
    try:
        tfidf_matrix = tfidf_vectorizer.fit_transform([text])
    except ValueError as e:
        if "empty vocabulary" in str(e):
            return []
        else:
            raise e
    feature_names = tfidf_vectorizer.get_feature_names_out()
    tfidf_scores = tfidf_matrix.toarray()[0]
    sorted_keywords = sorted(zip(feature_names, tfidf_scores), key=lambda x: x[1], reverse=True)
    return [word for word, score in sorted_keywords[:num_keywords]]

def extract_sentences(text, keywords, num_sentences=5):
    """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ë³„ë¡œ ë¶„ë¦¬í•˜ê³  í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ"""
    try:
        sentences = kss.split_sentences(text)
    except:
        sentences = text.split('.')
        
    if not sentences:
        return []
    keyword_dict = {word: 1 for word in keywords}
    sentence_scores = []
    for sentence in sentences:
        score = 0
        nouns_in_sentence = noun_tokenizer(sentence)
        for noun in nouns_in_sentence:
            if noun in keyword_dict:
                score += 1
        sentence_scores.append(score)
    sorted_sentence_indices = np.argsort(sentence_scores)[::-1]
    top_sentence_indices = sorted(sorted_sentence_indices[:num_sentences])
    key_sentences = [sentences[i] for i in top_sentence_indices]
    
    return key_sentences

# --------------------------------------------------------------------------
# [2] ì›¹ UI êµ¬ì„± (ì…ì¶œë ¥ ì—°ê²° - ê°œì„ ë¨)
# --------------------------------------------------------------------------

st.title("ğŸ“œ ê°•ì˜ ë…¸íŠ¸ ìš”ì•½ í”„ë¡œê·¸ë¨")
st.markdown("Command + Enterë¡œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

col1, col2 = st.columns(2)

with col1:
    st.subheader("ì…ë ¥")
    
    # [ë³€ê²½ì ] st.formì„ ì‚¬ìš©í•˜ì—¬ 'Command + Enter' ì§€ì› ë° ë²„íŠ¼ ìœ„ì¹˜ ê³ ì •
    with st.form(key='summary_form'):
        # heightë¥¼ 500 -> 250ìœ¼ë¡œ ì¤„ì—¬ì„œ ë²„íŠ¼ì´ ë°”ë¡œ ë³´ì´ê²Œ í•¨
        input_text = st.text_area("ê°•ì˜ ë…¸íŠ¸ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”", height=250)
        # í¼ ì œì¶œ ë²„íŠ¼ (ì´ê±¸ ëˆ„ë¥´ê±°ë‚˜, ì…ë ¥ì°½ì—ì„œ Cmd+Enter ì¹˜ë©´ ì‹¤í–‰ë¨)
        submit_btn = st.form_submit_button("ìš”ì•½ ì‹¤í–‰")

# ë²„íŠ¼ì„ ëˆ„ë¥´ê±°ë‚˜(submit_btn), í¼ ì•ˆì—ì„œ ì—”í„°ë¥¼ ì¹˜ë©´ ì‹¤í–‰ë¨
if submit_btn and input_text:
    
    # --- ì‚¬ìš©ì ì›ë³¸ ì‹¤í–‰ ë¡œì§ (ê·¸ëŒ€ë¡œ ìœ ì§€) ---
    lecture_note = re.sub(r'\s+', ' ', input_text)
    
    KEYWORD_RATIO = 0.2
    MIN_KEYWORDS = 5
    SENTENCE_RATIO = 0.3
    MIN_SENTENCES = 3

    all_nouns = noun_tokenizer(lecture_note)
    
    if not all_nouns:
        unique_noun_count = 0
        NUM_KEYWORDS = 0
    else:
        unique_noun_count = len(set(all_nouns))
        num_keywords = max(MIN_KEYWORDS, int(unique_noun_count * KEYWORD_RATIO))
        NUM_KEYWORDS = min(num_keywords, unique_noun_count)

    try:
        all_sentences = kss.split_sentences(lecture_note)
        total_sentence_count = len(all_sentences)
    except:
        total_sentence_count = lecture_note.count('.') 

    if total_sentence_count == 0:
        NUM_SENTENCES = 0
    else:
        num_sentences = max(MIN_SENTENCES, int(total_sentence_count * SENTENCE_RATIO))
        NUM_SENTENCES = min(num_sentences, total_sentence_count)

    keywords = extract_keywords(lecture_note, NUM_KEYWORDS)
    key_sentences = extract_sentences(lecture_note, keywords, NUM_SENTENCES)
    # ---------------------------------------------

    with col2:
        st.subheader("ê²°ê³¼")
        st.info(f"(ì „ì²´ ë¬¸ì¥: {total_sentence_count}ê°œ, ë¶„ì„ ëª…ì‚¬: {unique_noun_count}ê°œ)")
        
        st.markdown(f"#### ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ (ìƒìœ„ {NUM_KEYWORDS}ê°œ)")
        st.write(", ".join(keywords)) 
        
        st.divider()
        
        st.markdown(f"#### ğŸ¯ í•µì‹¬ ìš”ì•½ ë¬¸ì¥ (ìƒìœ„ {NUM_SENTENCES}ê°œ)")
        for i, sentence in enumerate(key_sentences):
            st.success(f"{i+1}. {sentence.strip()}")
            
elif submit_btn and not input_text:
    st.warning("ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
